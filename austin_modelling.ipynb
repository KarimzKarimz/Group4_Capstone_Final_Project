{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de9a440",
   "metadata": {},
   "source": [
    "# MODELLING OVERVIEW : Investment Type Recommender System\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- **Analysis-Based**  \n",
    "  Understand investment behaviors among Kenyan users and segment them based on patterns.\n",
    "\n",
    "\n",
    "- **Modeling-Based**  \n",
    "  Build and evaluate recommender models, including:\n",
    "  - Content-based filtering\n",
    "  - Hybrid approaches (clustering + classification)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dae41005",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "437fe391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>householdid</th>\n",
       "      <th>county</th>\n",
       "      <th>area_type</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_of_respondent</th>\n",
       "      <th>no_of_household_mebers</th>\n",
       "      <th>livelihoodcat</th>\n",
       "      <th>Quintiles</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital</th>\n",
       "      <th>...</th>\n",
       "      <th>insurance_including_NHIF_use</th>\n",
       "      <th>All_Insurance_excluding_NHIF_use</th>\n",
       "      <th>PWD</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>has_account</th>\n",
       "      <th>has_savings</th>\n",
       "      <th>has_credit</th>\n",
       "      <th>has_mobile</th>\n",
       "      <th>receives_remittance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107141431</td>\n",
       "      <td>garissa</td>\n",
       "      <td>urban</td>\n",
       "      <td>male</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>dependent</td>\n",
       "      <td>fourth</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>married/living with partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never used</td>\n",
       "      <td>never used</td>\n",
       "      <td>without disability</td>\n",
       "      <td>-0.435423</td>\n",
       "      <td>39.636586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10712933</td>\n",
       "      <td>garissa</td>\n",
       "      <td>urban</td>\n",
       "      <td>male</td>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>other</td>\n",
       "      <td>second</td>\n",
       "      <td>primary</td>\n",
       "      <td>married/living with partner</td>\n",
       "      <td>...</td>\n",
       "      <td>never used</td>\n",
       "      <td>never used</td>\n",
       "      <td>without disability</td>\n",
       "      <td>0.058794</td>\n",
       "      <td>40.305006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140173183</td>\n",
       "      <td>busia</td>\n",
       "      <td>urban</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>casual worker</td>\n",
       "      <td>fourth</td>\n",
       "      <td>primary</td>\n",
       "      <td>divorced/separated</td>\n",
       "      <td>...</td>\n",
       "      <td>never used</td>\n",
       "      <td>never used</td>\n",
       "      <td>without disability</td>\n",
       "      <td>0.636836</td>\n",
       "      <td>34.277390</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122137153</td>\n",
       "      <td>kiambu</td>\n",
       "      <td>urban</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>casual worker</td>\n",
       "      <td>middle</td>\n",
       "      <td>secondary</td>\n",
       "      <td>single/never married</td>\n",
       "      <td>...</td>\n",
       "      <td>never used</td>\n",
       "      <td>never used</td>\n",
       "      <td>without disability</td>\n",
       "      <td>-1.251917</td>\n",
       "      <td>36.719076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121193116</td>\n",
       "      <td>murang'a</td>\n",
       "      <td>urban</td>\n",
       "      <td>female</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>dependent</td>\n",
       "      <td>highest</td>\n",
       "      <td>secondary</td>\n",
       "      <td>single/never married</td>\n",
       "      <td>...</td>\n",
       "      <td>never used</td>\n",
       "      <td>never used</td>\n",
       "      <td>without disability</td>\n",
       "      <td>-0.795820</td>\n",
       "      <td>37.131085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 392 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   householdid    county area_type  gender  age_of_respondent  \\\n",
       "0    107141431   garissa     urban    male                 29   \n",
       "1     10712933   garissa     urban    male                 60   \n",
       "2    140173183     busia     urban  female                 35   \n",
       "3    122137153    kiambu     urban    male                 24   \n",
       "4    121193116  murang'a     urban  female                 20   \n",
       "\n",
       "   no_of_household_mebers  livelihoodcat Quintiles  Education  \\\n",
       "0                       5      dependent    fourth   tertiary   \n",
       "1                      11          other    second    primary   \n",
       "2                       2  casual worker    fourth    primary   \n",
       "3                       1  casual worker    middle  secondary   \n",
       "4                       1      dependent   highest  secondary   \n",
       "\n",
       "                       Marital  ...  insurance_including_NHIF_use  \\\n",
       "0  married/living with partner  ...                    never used   \n",
       "1  married/living with partner  ...                    never used   \n",
       "2           divorced/separated  ...                    never used   \n",
       "3         single/never married  ...                    never used   \n",
       "4         single/never married  ...                    never used   \n",
       "\n",
       "   All_Insurance_excluding_NHIF_use                 PWD  Latitude  Longitude  \\\n",
       "0                        never used  without disability -0.435423  39.636586   \n",
       "1                        never used  without disability  0.058794  40.305006   \n",
       "2                        never used  without disability  0.636836  34.277390   \n",
       "3                        never used  without disability -1.251917  36.719076   \n",
       "4                        never used  without disability -0.795820  37.131085   \n",
       "\n",
       "   has_account has_savings has_credit has_mobile receives_remittance  \n",
       "0            0           0          0          0                   0  \n",
       "1            0           0          0          0                   0  \n",
       "2            0           0          0          0                   0  \n",
       "3            0           0          0          0                   0  \n",
       "4            0           0          0          0                   0  \n",
       "\n",
       "[5 rows x 392 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "file_path = \"C:/Users/hp/Documents/Group4_Capstone_Final_Project/final_refined.csv\"\n",
    "\n",
    "invest_df = pd.read_csv(file_path)\n",
    "invest_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d34944e",
   "metadata": {},
   "source": [
    " # **Investment Modelling pipeline**\n",
    " Emulating a object oriented approach with our **class** `InvestmentPipeline`.We are defining the structure of our pipeline before calling \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4ea0e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvestmentPipeline:\n",
    "    def __init__(self):\n",
    "        # Initialize models, scalers, configs, etc.\n",
    "        pass\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"\n",
    "        General preprocessing: handle missing values, encode, scale, etc.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def prepare_transactions(self, df):\n",
    "        \"\"\"\n",
    "        Converts binary features (0/1) into boolean format for association rule mining.\n",
    "        Assumes input features are already numeric and binary.\n",
    "        \"\"\"\n",
    "        df_bool = df.copy()\n",
    "\n",
    "        # Identify binary columns (only 0 and 1 values)\n",
    "        binary_cols = [col for col in df_bool.columns if set(df_bool[col].dropna().unique()) <= {0, 1}]\n",
    "        df_bool = df_bool[binary_cols]\n",
    "\n",
    "        # Convert to boolean\n",
    "        df_bool = df_bool.astype(bool)\n",
    "\n",
    "        return df_bool\n",
    "\n",
    "    def mine_association_rules(self, df_bool, min_support=0.1, min_confidence=0.5):\n",
    "        \"\"\"\n",
    "        Mine frequent itemsets and extract association rules.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def cluster_investors(self, df, n_clusters=3):\n",
    "        \"\"\"\n",
    "        Apply clustering (e.g., K-Means) to segment investors.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def recommend_investments(self, investor_profile):\n",
    "        \"\"\"\n",
    "        Recommend investments based on rules or cluster profiles.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def explain_model(self, model, X):\n",
    "        \"\"\"\n",
    "        Use SHAP or PCA to visualize and interpret model decisions.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b5fc22",
   "metadata": {},
   "source": [
    "## **Feature Separation**\n",
    "###  Preprocesses the dataset:\n",
    "        - Imputes and scales numeric features\n",
    "        - Imputes and encodes categorical features\n",
    "        - Returns a transformed DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5943f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline as SKPipeline\n",
    "\n",
    "class InvestmentPipeline:\n",
    "    def __init__(self):\n",
    "        # Define preprocessing for numeric and categorical features\n",
    "        self.numeric_transformer = SKPipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        self.categorical_transformer = SKPipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        self.preprocessor = None  # Will be set after fitting\n",
    "\n",
    "    def preprocess_data(self, invest_df):\n",
    "        \n",
    "        invest_df_clean = invest_df.copy()\n",
    "\n",
    "        # Step 1: Identify column types\n",
    "        numeric_cols = invest_df_clean.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        categorical_cols = invest_df_clean.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "        # Step 2: Create column transformer\n",
    "        self.preprocessor = ColumnTransformer(transformers=[\n",
    "            ('num', self.numeric_transformer, numeric_cols),\n",
    "            ('cat', self.categorical_transformer, categorical_cols)\n",
    "        ])\n",
    "\n",
    "        # Step 3: Fit and transform\n",
    "        invest_df_transformed = self.preprocessor.fit_transform(invest_df_clean)\n",
    "\n",
    "        # Step 4: Get feature names\n",
    "        num_features = numeric_cols\n",
    "        cat_features = self.preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_cols)\n",
    "        all_features = list(num_features) + list(cat_features)\n",
    "\n",
    "        # Step 5: Return as DataFrame\n",
    "        return pd.DataFrame(invest_df_transformed, columns=all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e6213d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "class InvestmentPipeline:\n",
    "    def __init__(self):\n",
    "        # Initialize transformers\n",
    "        self.numeric_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        self.categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        self.preprocessor = None  # Will be defined after fitting\n",
    "\n",
    "    def preprocess_data(self, invest_df):\n",
    "        \"\"\"\n",
    "        Preprocess the raw investment data:\n",
    "        - Impute missing values\n",
    "        - Encode categorical features\n",
    "        - Scale numeric features\n",
    "        \"\"\"\n",
    "        invest_df_clean = invest_df.copy()\n",
    "\n",
    "        # Separate numeric and categorical columns\n",
    "        numeric_cols = invest_df_clean.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        categorical_cols = invest_df_clean.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "        # Combine transformers\n",
    "        self.preprocessor = ColumnTransformer(transformers=[\n",
    "            ('num', self.numeric_transformer, numeric_cols),\n",
    "            ('cat', self.categorical_transformer, categorical_cols)\n",
    "        ])\n",
    "\n",
    "        # Apply transformations\n",
    "        invest_df_processed = self.preprocessor.fit_transform(invest_df_clean)\n",
    "\n",
    "        # Get feature names\n",
    "        num_features = numeric_cols\n",
    "        cat_features = self.preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_cols)\n",
    "        all_features = list(num_features) + list(cat_features)\n",
    "\n",
    "        # Return as DataFrame\n",
    "        return pd.DataFrame(invest_df_processed, columns=all_features)\n",
    "\n",
    "    def prepare_transactions(self, invest_df):\n",
    "        \"\"\"\n",
    "        Converts binary features (0/1) into boolean format for association rule mining.\n",
    "        Assumes input features are already numeric and binary.\n",
    "        \"\"\"\n",
    "        invest_df_bool = invest_df.copy()\n",
    "\n",
    "        # Identify binary columns (only 0 and 1 values)\n",
    "        binary_cols = [col for col in invest_df_bool.columns if set(invest_df_bool[col].dropna().unique()) <= {0, 1}]\n",
    "        invest_df_bool = invest_df_bool[binary_cols]\n",
    "\n",
    "        # Convert to boolean\n",
    "        invest_df_bool = invest_df_bool.astype(bool)\n",
    "\n",
    "        return invest_df_bool\n",
    "\n",
    "    def mine_association_rules(self, invest_df_bool, min_support=0.1, min_confidence=0.5):\n",
    "        \"\"\"\n",
    "        Mine frequent itemsets and extract association rules.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def cluster_investors(self, invest_df, n_clusters=3):\n",
    "        \"\"\"\n",
    "        Apply clustering (e.g., K-Means) to segment investors.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def recommend_investments(self, investor_profile):\n",
    "        \"\"\"\n",
    "        Recommend investments based on rules or cluster profiles.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def explain_model(self, model, X):\n",
    "        \"\"\"\n",
    "        Use SHAP or PCA to visualize and interpret model decisions.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0c89a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b36f4b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   householdid  age_of_respondent  no_of_household_mebers  CalcExpenditure  \\\n",
      "0    -0.245766          -0.596843                0.312049         3.293907   \n",
      "1    -0.559097           1.204477                2.700016        -0.021234   \n",
      "2    -0.138433          -0.248200               -0.881934         0.969329   \n",
      "3    -0.197039          -0.887378               -1.279928        -0.484404   \n",
      "4    -0.200107          -1.119806               -1.279928         0.222393   \n",
      "\n",
      "   total_monthly_expenditure  no_respodent_per_hh  hhWeight  \\\n",
      "0                   4.096836            -0.591811 -0.308792   \n",
      "1                   0.425916             1.207526 -0.914595   \n",
      "2                   0.066022            -0.243553 -0.456369   \n",
      "3                  -0.401840            -0.882027  2.757352   \n",
      "4                  -0.509808            -1.114200 -0.348454   \n",
      "\n",
      "   Informal_group_membership  Above16_Total  Above16  ...  \\\n",
      "0                  -0.160662      -0.096354      0.0  ...   \n",
      "1                  -0.160662      -0.096354      0.0  ...   \n",
      "2                   0.292287      -0.955394      0.0  ...   \n",
      "3                  -0.160662      -0.955394      0.0  ...   \n",
      "4                  -0.160662      -0.955394      0.0  ...   \n",
      "\n",
      "   using_someone_acc_no  using_someone_acc_yes  \\\n",
      "0                   0.0                    1.0   \n",
      "1                   0.0                    1.0   \n",
      "2                   0.0                    1.0   \n",
      "3                   0.0                    1.0   \n",
      "4                   0.0                    1.0   \n",
      "\n",
      "   insurance_including_NHIF_use_currently use  \\\n",
      "0                                         0.0   \n",
      "1                                         0.0   \n",
      "2                                         0.0   \n",
      "3                                         0.0   \n",
      "4                                         0.0   \n",
      "\n",
      "   insurance_including_NHIF_use_never used  \\\n",
      "0                                      1.0   \n",
      "1                                      1.0   \n",
      "2                                      1.0   \n",
      "3                                      1.0   \n",
      "4                                      1.0   \n",
      "\n",
      "   insurance_including_NHIF_use_used to use  \\\n",
      "0                                       0.0   \n",
      "1                                       0.0   \n",
      "2                                       0.0   \n",
      "3                                       0.0   \n",
      "4                                       0.0   \n",
      "\n",
      "   All_Insurance_excluding_NHIF_use_currently use  \\\n",
      "0                                             0.0   \n",
      "1                                             0.0   \n",
      "2                                             0.0   \n",
      "3                                             0.0   \n",
      "4                                             0.0   \n",
      "\n",
      "   All_Insurance_excluding_NHIF_use_never used  \\\n",
      "0                                          1.0   \n",
      "1                                          1.0   \n",
      "2                                          1.0   \n",
      "3                                          1.0   \n",
      "4                                          1.0   \n",
      "\n",
      "   All_Insurance_excluding_NHIF_use_used to use  PWD_with disability  \\\n",
      "0                                           0.0                  0.0   \n",
      "1                                           0.0                  0.0   \n",
      "2                                           0.0                  0.0   \n",
      "3                                           0.0                  0.0   \n",
      "4                                           0.0                  0.0   \n",
      "\n",
      "   PWD_without disability  \n",
      "0                     1.0  \n",
      "1                     1.0  \n",
      "2                     1.0  \n",
      "3                     1.0  \n",
      "4                     1.0  \n",
      "\n",
      "[5 rows x 967 columns]\n"
     ]
    }
   ],
   "source": [
    "pipeline = InvestmentPipeline()\n",
    "\n",
    "# Step 1: Preprocess your raw investment data\n",
    "invest_df_scaled = pipeline.preprocess_data(invest_df)\n",
    "\n",
    "# Step 2: Inspect the result\n",
    "print(invest_df_scaled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bdd7ff",
   "metadata": {},
   "source": [
    "## **Associate Rule Mining Method to the Class**\n",
    "###  In our existing pipeline, using `mlxtend` for rule extraction and `networkx` and `matplotlib` for visualizations\n",
    "### install Required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9408fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (0.23.4)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from mlxtend) (1.5.0)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from mlxtend) (1.3.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from mlxtend) (0.17.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from mlxtend) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from mlxtend) (1.18.5)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from networkx) (4.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from matplotlib) (8.0.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from matplotlib) (2025.6.15)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (2.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2020.1)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\envs\\learn-env\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend networkx matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1bf921",
   "metadata": {},
   "source": [
    "## Update the Pipeline with our Class **prepare_transactions()** for Rule Mining.\n",
    "### Preprocessing our data into a transactional format suitable for `APriori`.Converting  binary financial features into boolean format for rule mining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ef44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_transactions(self, invest_df):\n",
    "  \n",
    "    invest_df_bool = invest_df.copy()\n",
    "\n",
    "    # Only keep binary columns (0/1)\n",
    "    binary_cols = [col for col in invest_df_bool.columns if set(invest_df_bool[col].unique()) <= {0, 1}]\n",
    "    invest_df_bool = invest_df_bool[binary_cols]\n",
    "\n",
    "    # Convert to boolean\n",
    "    invest_df_bool = invest_df_bool.astype(bool)\n",
    "\n",
    "    return invest_df_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6ac9b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'InvestmentPipeline' object has no attribute 'prepare_transactions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-f1af95dc68dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minvest_df_bool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_transactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvest_df_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvest_df_bool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvest_df_bool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'InvestmentPipeline' object has no attribute 'prepare_transactions'"
     ]
    }
   ],
   "source": [
    "invest_df_bool = pipeline.prepare_transactions(invest_df_scaled)\n",
    "print(invest_df_bool.head())\n",
    "print(invest_df_bool.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f917a40b",
   "metadata": {},
   "source": [
    "## **Extract Rules with Apriori**\n",
    "### Add this method to your class,Mines frequent itemsets and association rules.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df45f2e6",
   "metadata": {},
   "source": [
    "## **Visualize Rules as a Graph**\n",
    "### This helps stakeholders see how financial behaivours relate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49cd737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
